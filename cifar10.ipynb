{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer randCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 256, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "    return recv()\n",
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "    racquire()\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "KeyboardInterrupt\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3c498c8892dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0ml1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfcw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-ebdd44f36375>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net3 = rand_Net3()\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, fcw = net3(inputs)\n",
    "        \n",
    "        \n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001, momentum=0.9)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        l1 = torch.abs(fcw).sum()\n",
    "        #print('CRIT', criterion(outputs, labels))\n",
    "        #print('L1', l1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) + 0.001*l1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 55 %\n",
      "Accuracy of   car : 44 %\n",
      "Accuracy of  bird : 15 %\n",
      "Accuracy of   cat : 12 %\n",
      "Accuracy of  deer : 40 %\n",
      "Accuracy of   dog : 42 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 56 %\n",
      "Accuracy of truck : 59 %\n",
      "0.4321\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs,_ = net3(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(8):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 512, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),kernel_size=2, stride=2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.305\n",
      "[1,  4000] loss: 2.303\n",
      "[1,  6000] loss: 2.302\n",
      "[2,  2000] loss: 2.302\n",
      "[2,  4000] loss: 2.301\n",
      "[2,  6000] loss: 2.300\n",
      "[3,  2000] loss: 2.300\n",
      "[3,  4000] loss: 2.299\n",
      "[3,  6000] loss: 2.299\n",
      "[4,  2000] loss: 2.299\n",
      "[4,  4000] loss: 2.298\n",
      "[4,  6000] loss: 2.297\n",
      "[5,  2000] loss: 2.297\n",
      "[5,  4000] loss: 2.297\n",
      "[5,  6000] loss: 2.296\n",
      "[6,  2000] loss: 2.296\n",
      "[6,  4000] loss: 2.295\n",
      "[6,  6000] loss: 2.295\n",
      "[7,  2000] loss: 2.295\n",
      "[7,  4000] loss: 2.294\n",
      "[7,  6000] loss: 2.294\n",
      "[8,  2000] loss: 2.293\n",
      "[8,  4000] loss: 2.293\n",
      "[8,  6000] loss: 2.293\n",
      "[9,  2000] loss: 2.293\n",
      "[9,  4000] loss: 2.292\n",
      "[9,  6000] loss: 2.291\n",
      "[10,  2000] loss: 2.292\n",
      "[10,  4000] loss: 2.290\n",
      "[10,  6000] loss: 2.291\n",
      "[11,  2000] loss: 2.290\n",
      "[11,  4000] loss: 2.290\n",
      "[11,  6000] loss: 2.289\n",
      "[12,  2000] loss: 2.289\n",
      "[12,  4000] loss: 2.289\n",
      "[12,  6000] loss: 2.289\n",
      "[13,  2000] loss: 2.288\n",
      "[13,  4000] loss: 2.288\n",
      "[13,  6000] loss: 2.287\n",
      "[14,  2000] loss: 2.287\n",
      "[14,  4000] loss: 2.287\n",
      "[14,  6000] loss: 2.286\n",
      "[15,  2000] loss: 2.286\n",
      "[15,  4000] loss: 2.285\n",
      "[15,  6000] loss: 2.285\n",
      "[16,  2000] loss: 2.285\n",
      "[16,  4000] loss: 2.284\n",
      "[16,  6000] loss: 2.284\n",
      "[17,  2000] loss: 2.283\n",
      "[17,  4000] loss: 2.284\n",
      "[17,  6000] loss: 2.284\n",
      "[18,  2000] loss: 2.283\n",
      "[18,  4000] loss: 2.283\n",
      "[18,  6000] loss: 2.282\n",
      "[19,  2000] loss: 2.282\n",
      "[19,  4000] loss: 2.281\n",
      "[19,  6000] loss: 2.281\n",
      "[20,  2000] loss: 2.281\n",
      "[20,  4000] loss: 2.280\n",
      "[20,  6000] loss: 2.281\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net4 = rand_Net4()\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        \n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, fcw = net4(inputs)\n",
    "        \n",
    "        \n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001, momentum=0.9)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        l1 = torch.abs(fcw).sum()\n",
    "        #print('CRIT', criterion(outputs, labels))\n",
    "        #print('L1', l1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) + 0.001*l1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 47 %\n",
      "Accuracy of   car : 34 %\n",
      "Accuracy of  bird :  1 %\n",
      "Accuracy of   cat :  0 %\n",
      "Accuracy of  deer : 59 %\n",
      "Accuracy of   dog : 39 %\n",
      "Accuracy of  frog : 22 %\n",
      "Accuracy of horse : 20 %\n",
      "Accuracy of  ship : 59 %\n",
      "Accuracy of truck : 65 %\n",
      "0.3493\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs,_ = net4(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(8):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vgg11 [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "   \n",
    "class rand_vgg11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_vgg11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "                \n",
    "        self.conv6 = nn.Conv2d(256, 512, 3,padding=1)\n",
    "        self.conv7 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "        self.conv9 = nn.Conv2d(512, 512, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(2048, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv4(x),kernel_size=2, stride=2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute purely on pixels\n",
      "1\n",
      "-----\n",
      "Accuracy of plane : 44 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat : 19 %\n",
      "Accuracy of  deer : 30 %\n",
      "Accuracy of   dog : 30 %\n",
      "Accuracy of  frog : 53 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 50 %\n",
      "Accuracy of truck : 38 %\n",
      "0.3828\n",
      "-----\n",
      "Accuracy of plane : 44 %\n",
      "Accuracy of   car : 47 %\n",
      "Accuracy of  bird : 29 %\n",
      "Accuracy of   cat : 16 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 40 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 64 %\n",
      "Accuracy of truck : 56 %\n",
      "0.4408\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics,preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('compute purely on pixels')\n",
    "for ty,data in enumerate(trainloader):\n",
    "    images, labels = data\n",
    "    for alpha in [1]:#np.logspace(0,3,10):\n",
    "        print alpha\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=3)\n",
    "        rf = RandomForestClassifier(n_estimators = 500,n_jobs=6)\n",
    "        reg.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "        rf.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "    for mod in [reg,rf]:\n",
    "        print (\"-----\")\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        for a,data in enumerate(testloader):\n",
    "            imagesp, labelsp = data\n",
    "            predicted = mod.predict(imagesp[:,:,:,:].numpy().reshape(500,-1))\n",
    "            c = (predicted == labelsp).squeeze()\n",
    "            for i in range(500):\n",
    "                label = labelsp[i]\n",
    "                class_correct[label] += c[i]\n",
    "                class_total[label] += 1\n",
    "            if a>=4:\n",
    "                break \n",
    "        for i in range(10):\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print np.sum(class_correct)/np.sum(class_total)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nest is 500\n",
      "((7000, 512), torch.Size([7000]))\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=6,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy of plane : 40 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat :  9 %\n",
      "Accuracy of  deer : 29 %\n",
      "Accuracy of   dog : 37 %\n",
      "Accuracy of  frog : 56 %\n",
      "Accuracy of horse : 44 %\n",
      "Accuracy of  ship : 51 %\n",
      "Accuracy of truck : 39 %\n",
      "0.3788\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=300, multi_class='ovr', n_jobs=6,\n",
      "          penalty='l1', random_state=None, solver='saga', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy of plane : 45 %\n",
      "Accuracy of   car : 54 %\n",
      "Accuracy of  bird : 27 %\n",
      "Accuracy of   cat : 20 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 31 %\n",
      "Accuracy of  frog : 63 %\n",
      "Accuracy of horse : 49 %\n",
      "Accuracy of  ship : 58 %\n",
      "Accuracy of truck : 46 %\n",
      "0.4344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model,metrics,preprocessing\n",
    "\n",
    "\n",
    "for ty,data in enumerate(trainloader):\n",
    "    mrand_Net = rand_Net_3() \n",
    "    images, labels = data\n",
    "    outputs = mrand_Net(Variable(images))\n",
    "    if True: #for nest in [500]:#np.logspace(0,3,10):\n",
    "        print('nest is %s'%nest)\n",
    "        print(outputs.data.numpy().shape, labels.shape)\n",
    "        rf = RandomForestClassifier(n_estimators=700, n_jobs=6)\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=300)\n",
    "        \n",
    "        rf.fit(outputs.data.numpy(), labels) \n",
    "        reg.fit(outputs.data.numpy(), labels) \n",
    "        \n",
    "        for mod in [rf,reg]:\n",
    "            print(mod)\n",
    "            class_correct = list(0. for i in range(10))\n",
    "            class_total = list(0. for i in range(10))\n",
    "            for a, data in enumerate(testloader):\n",
    "                imagesp, labelsp = data\n",
    "                outputsp = mrand_Net(Variable(imagesp))\n",
    "                predicted = mod.predict(outputsp.data.numpy())\n",
    "                c = (predicted == labelsp).squeeze()\n",
    "                for i in range(500):\n",
    "                    label = labelsp[i]\n",
    "                    class_correct[label] += c[i]\n",
    "                    class_total[label] += 1\n",
    "                if a>=4:\n",
    "                    break   \n",
    "            for i in range(10):\n",
    "                print('Accuracy of %5s : %2d %%' % (\n",
    "                    classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "            print np.sum(class_correct)/np.sum(class_total)\n",
    "        #L.append(metrics.log_loss(np.array(labels_t),yout ,labels=range(10)))       \n",
    "    #print(L, L_lr) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
