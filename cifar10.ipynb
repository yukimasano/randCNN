{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "os.environ['MKL_NUM_THREADS'] = \"8\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"8\"\n",
    "OMP_NUM_THREADS=8\n",
    "MKL_NUM_THREADS=8\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpu=False\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 30 epochs\"\"\"\n",
    "    lr = 0.05 * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def train_eval(net,n_epochs=50):\n",
    "    losses=[]\n",
    "    if gpu==True:\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            if gpu==True:\n",
    "                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "            # forward + backward + optimize\n",
    "            outputs, fcw = net(inputs)\n",
    "\n",
    "            #optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001, momentum=0.9)\n",
    "            \n",
    "            optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), \n",
    "                                  lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "            adjust_learning_rate(optimizer, epoch)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l1 = torch.abs(fcw).sum()\n",
    "            #print('CRIT', criterion(outputs, labels))\n",
    "            #print('L1', l1)\n",
    "\n",
    "            loss = criterion(outputs, labels) #+ 0.001*l1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                losses.append(running_loss/ 2000)\n",
    "                running_loss = 0.0\n",
    "                #print('L1 = %s'%l1)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    plt.plot(losses)\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        if gpu==True:                                 \n",
    "            outputs,_ = net(Variable(images).cuda())\n",
    "            _, predicted = torch.max(outputs.data.cpu(), 1)\n",
    "        else:\n",
    "            outputs,_ = net(Variable(images))\n",
    "            _, predicted = torch.max(outputs.data, 1)                               \n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(8):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer randCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 512, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.985\n",
      "[2,  2000] loss: 1.732\n",
      "[3,  2000] loss: 1.642\n",
      "[4,  2000] loss: 1.598\n",
      "[5,  2000] loss: 1.560\n",
      "[6,  2000] loss: 1.532\n",
      "[7,  2000] loss: 1.524\n",
      "[8,  2000] loss: 1.497\n",
      "[9,  2000] loss: 1.485\n",
      "[10,  2000] loss: 1.476\n",
      "[11,  2000] loss: 1.470\n",
      "[12,  2000] loss: 1.464\n",
      "[13,  2000] loss: 1.459\n",
      "[14,  2000] loss: 1.448\n",
      "[15,  2000] loss: 1.441\n",
      "[16,  2000] loss: 1.441\n",
      "[17,  2000] loss: 1.433\n",
      "[18,  2000] loss: 1.431\n",
      "[19,  2000] loss: 1.439\n",
      "[20,  2000] loss: 1.426\n",
      "[21,  2000] loss: 1.431\n",
      "[22,  2000] loss: 1.423\n",
      "[23,  2000] loss: 1.414\n",
      "[24,  2000] loss: 1.419\n",
      "[25,  2000] loss: 1.424\n",
      "[26,  2000] loss: 1.425\n",
      "[27,  2000] loss: 1.426\n",
      "[28,  2000] loss: 1.409\n",
      "[29,  2000] loss: 1.423\n",
      "[30,  2000] loss: 1.423\n",
      "[31,  2000] loss: 1.318\n",
      "[32,  2000] loss: 1.308\n",
      "[33,  2000] loss: 1.318\n",
      "[34,  2000] loss: 1.323\n",
      "[35,  2000] loss: 1.317\n",
      "[36,  2000] loss: 1.314\n",
      "[37,  2000] loss: 1.321\n",
      "[38,  2000] loss: 1.321\n",
      "[39,  2000] loss: 1.321\n",
      "[40,  2000] loss: 1.315\n",
      "[41,  2000] loss: 1.317\n",
      "[42,  2000] loss: 1.318\n",
      "[43,  2000] loss: 1.314\n",
      "[44,  2000] loss: 1.315\n",
      "[45,  2000] loss: 1.328\n",
      "[46,  2000] loss: 1.321\n",
      "[47,  2000] loss: 1.323\n",
      "[48,  2000] loss: 1.317\n",
      "[49,  2000] loss: 1.322\n",
      "[50,  2000] loss: 1.318\n",
      "[51,  2000] loss: 1.327\n",
      "[52,  2000] loss: 1.323\n",
      "[53,  2000] loss: 1.318\n",
      "[54,  2000] loss: 1.320\n",
      "[55,  2000] loss: 1.324\n",
      "[56,  2000] loss: 1.320\n",
      "[57,  2000] loss: 1.317\n",
      "[58,  2000] loss: 1.324\n",
      "[59,  2000] loss: 1.325\n",
      "[60,  2000] loss: 1.321\n",
      "[61,  2000] loss: 1.284\n",
      "[62,  2000] loss: 1.285\n",
      "[63,  2000] loss: 1.286\n",
      "[64,  2000] loss: 1.290\n",
      "[65,  2000] loss: 1.289\n",
      "[66,  2000] loss: 1.286\n",
      "[67,  2000] loss: 1.287\n",
      "[68,  2000] loss: 1.286\n",
      "[69,  2000] loss: 1.290\n",
      "[70,  2000] loss: 1.286\n",
      "[71,  2000] loss: 1.285\n",
      "[72,  2000] loss: 1.292\n",
      "[73,  2000] loss: 1.285\n",
      "[74,  2000] loss: 1.288\n",
      "[75,  2000] loss: 1.284\n",
      "[76,  2000] loss: 1.288\n",
      "[77,  2000] loss: 1.288\n",
      "[78,  2000] loss: 1.295\n",
      "[79,  2000] loss: 1.292\n",
      "[80,  2000] loss: 1.286\n",
      "[81,  2000] loss: 1.284\n",
      "[82,  2000] loss: 1.289\n",
      "[83,  2000] loss: 1.292\n",
      "[84,  2000] loss: 1.296\n",
      "[85,  2000] loss: 1.294\n",
      "[86,  2000] loss: 1.291\n",
      "[87,  2000] loss: 1.292\n",
      "[88,  2000] loss: 1.289\n",
      "[89,  2000] loss: 1.288\n",
      "[90,  2000] loss: 1.285\n",
      "[91,  2000] loss: 1.270\n",
      "[92,  2000] loss: 1.269\n",
      "[93,  2000] loss: 1.273\n",
      "[94,  2000] loss: 1.273\n",
      "[95,  2000] loss: 1.277\n",
      "[96,  2000] loss: 1.275\n",
      "[97,  2000] loss: 1.273\n",
      "[98,  2000] loss: 1.268\n",
      "[99,  2000] loss: 1.275\n",
      "[100,  2000] loss: 1.274\n",
      "Finished Training\n",
      "Accuracy of plane : 70 %\n",
      "Accuracy of   car : 82 %\n",
      "Accuracy of  bird : 36 %\n",
      "Accuracy of   cat : 40 %\n",
      "Accuracy of  deer : 56 %\n",
      "Accuracy of   dog : 55 %\n",
      "Accuracy of  frog : 70 %\n",
      "Accuracy of horse : 65 %\n",
      "Accuracy of  ship : 69 %\n",
      "Accuracy of truck : 59 %\n",
      "0.6068\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd8VNed9/HPb5p6A0kIBEJgejEYC2zcgkkct7jGcYyTuKR4s+vNpr0SO8nuk3U2T7LZ7GZjP07sJbZDnDg4jkviknjjuIAdA0aYanqxQBQVUO+aOc8fM2CKGmLEMKPv+/XSC83M0b2/qyu+c+bcc+815xwiIpJYPLEuQEREok/hLiKSgBTuIiIJSOEuIpKAFO4iIglI4S4ikoAU7iIiCUjhLiKSgBTuIiIJyBerFefm5rri4uJYrV5EJC6tWrWq2jmX11u7mIV7cXExpaWlsVq9iEhcMrOyvrTrdVjGzEaZ2etmtsnM3jOzL3fRxszsATPbbmbrzGxWf4oWEZHo6EvPvRP4unPuXTPLAFaZ2SvOuY1HtbkSGB/5Og94KPKviIjEQK89d+fcfufcu5HvG4BNQOFxza4DHndhy4FsMxse9WpFRKRPTmq2jJkVA+cAK457qRDYc9Tjck58AxARkdOkz+FuZunAM8BXnHP1x7/cxY+ccKF4M7vLzErNrLSqqurkKhURkT7rU7ibmZ9wsD/hnHu2iyblwKijHo8E9h3fyDm30DlX4pwrycvrdSaPiIj0U19myxjwKLDJOfeTbpo9D9wWmTVzPlDnnNsfxTpFROQk9GW2zIXAZ4D1ZrYm8ty3gSIA59zDwJ+Aq4DtQDNwZ/RLDdtyoIEX1u7jsxeNYUhaYKBWIyIS13oNd+fcW3Q9pn50GwfcHa2ierKzqpEHX9/O1WcPV7iLiHQj7q4tkxLwAtDcHoxxJSIiZ664C/e0pPCHjRaFu4hIt+Iu3FP8h3vunTGuRETkzBV34Z6qYRkRkV7FXbgfHpZRuIuIdC/uwv2DA6oalhER6U7chXuqX8MyIiK9ibtw93k9BLwehbuISA/iLtwBUpO8tGhYRkSkW/EZ7n4vTeq5i4h0Ky7DPSXg1UlMIiI9iMtwT0vyabaMiEgP4jLcU/xeHVAVEelBXIZ7akDhLiLSkzgNdw3LiIj0JE7DXQdURUR6ErfhrqmQIiLdi8twTwn41HMXEelBXIZ7WsBLezBERzAU61JERM5IvYa7mT1mZpVmtqGb13PM7DkzW2dm75jZtOiXeSzdak9EpGd96bkvAq7o4fVvA2ucc2cDtwH3R6GuHqUGdKs9EZGe9BruzrmlwKEemkwBXo203QwUm9mw6JTXtVRd011EpEfRGHNfC9wIYGZzgNHAyCgst1u61Z6ISM+iEe7/DuSY2RrgS8BqoMsutZndZWalZlZaVVXV7xUeHpZRuIuIdM13qgtwztUDdwKYmQG7Il9dtV0ILAQoKSlx/V2nbrUnItKzU+65m1m2mQUiDz8PLI0E/oBJSwqHuw6oioh0rdeeu5ktBuYBuWZWDnwX8AM45x4GJgOPm1kQ2Ah8bsCqjUj1h8vWWaoiIl3rNdydcwt6eX0ZMD5qFfXB4WEZ3WpPRKRrcXmGqmbLiIj0LC7DPcWvcBcR6UlchrvHY5G7MWlYRkSkK3EZ7qC7MYmI9CR+wz1JN+wQEelO/Ia730eThmVERLoUt+GeomEZEZFuxW246z6qIiLdi+Nw9+kMVRGRbsRxuHt1hqqISDfiOtw15i4i0rU4DnefxtxFRLoRx+Hupam9E+f6fVl4EZGEFbfhnhLwEnLQ1hmKdSkiImecuA331IBu2CEi0p24Dfe0wOEbdmjGjIjI8eI23FPUcxcR6Vbchrtu2CEi0r04DvfwsIzCXUTkRL2Gu5k9ZmaVZrahm9ezzOwFM1trZu+Z2Z3RL/NEH/TcNeYuInK8vvTcFwFX9PD63cBG59wMYB7wX2YWOPXSeqZhGRGR7vUa7s65pcChnpoAGWZmQHqk7YB3p3VAVUSke9EYc38QmAzsA9YDX3bOdXlmkZndZWalZlZaVVV1SivVVEgRke5FI9wvB9YAI4CZwINmltlVQ+fcQudciXOuJC8v75RWmqJhGRGRbkUj3O8EnnVh24FdwKQoLLdHST4PHtOwjIhIV6IR7ruBDwOY2TBgIrAzCsvtkZmRFtB9VEVEuuLrrYGZLSY8CybXzMqB7wJ+AOfcw8C/AYvMbD1gwD3OueoBq/goKbrVnohIl3oNd+fcgl5e3wd8NGoVnQTdsENEpGtxe4YqQErAp3AXEelCXId7WsCrM1RFRLoQ1+GeomEZEZEuxXW4p+qAqohIl+I63DUVUkSka3Ed7poKKSLStbgOd02FFBHpWlyHe0rAR0tHkFDIxboUEZEzSlyHe9rhy/52qPcuInK0uA533bBDRKRrcR3uKZFruuugqojIseI63A8Py2g6pIjIseI63HXDDhGRrsV1uA9JC9+Hu7qxLcaViIicWeI63EfmpAKwt6YlxpWIiJxZ4jrcc1L9pAa8lCvcRUSOEdfhbmYUZqdQXtMc61JERM4ocR3uACNzUthbq567iMjReg13M3vMzCrNbEM3r3/DzNZEvjaYWdDMhkS/1K6NzEnVsIyIyHH60nNfBFzR3YvOuR8752Y652YC3wKWOOcORam+XhXmpFDX0kFDa8fpWqWIyBmv13B3zi0F+hrWC4DFp1TRSRqZkwKgoRkRkaNEbczdzFIJ9/CfidYy++LwdMjyQwp3EZHDonlA9Rrgbz0NyZjZXWZWamalVVVVUVlpYXa4564ZMyIiH4hmuN9CL0MyzrmFzrkS51xJXl5eVFaamx4gyefRsIyIyFGiEu5mlgV8CPhjNJZ3kutmZE6KZsyIiBzF11sDM1sMzANyzawc+C7gB3DOPRxpdgPwF+dc0wDV2aPCnFT13EVEjtJruDvnFvShzSLCUyZjYmROChv21sVq9SIiZ5y4P0MVwuF+qKmdZl3XXUQESJBwPzxjRleHFBEJS4hwPzLXXeEuIgIkSLiPytFcdxGRoyVEuOemJxHweijXjBkRESBBwt3jMQo1111E5IiECHdAJzKJiBwlYcK9MDtFs2VERCISJtxH5qRQ3dhGa0cw1qWIiMRcAoW7pkOKiByWQOEeng65R9MhRUQSJ9wnFGTgMVhdVhPrUkREYi5hwj0z2c/0wiyW7TwY61JERGIuYcId4PyzhrJmTy0t7TqoKiKDW0KF+9yxQ+kIOkrL+no/bxGRxJRQ4T67eAg+j/H2Dg3NiMjgllDhnpbkY8aobJYp3EVkkEuocIfw0Mz6vXU0tunGHSIyeCVeuJ81lGDIsXKXxt1FZPDqNdzN7DEzqzSzDT20mWdma8zsPTNbEt0ST865o3MIeD2aEikig1pfeu6LgCu6e9HMsoGfA9c656YCn4hOaf2T7PdyTlE2b++ojmUZIiIx1Wu4O+eWAj2NcdwKPOuc2x1pXxml2vpt7llDeW9fPXXNHbEuRUQkJqIx5j4ByDGzN8xslZnd1l1DM7vLzErNrLSqqioKq+7a3LFDcQ6W79LQjIgMTtEIdx9wLnA1cDnwL2Y2oauGzrmFzrkS51xJXl5eFFbdtXOKckgLeFmydeDeQEREzmS+KCyjHKh2zjUBTWa2FJgBbI3Csvsl4PNw8fg8Xt9ciXMOM4tVKSIiMRGNnvsfgYvNzGdmqcB5wKYoLPeUzJ+Uz/66Vjbtb4h1KSIip12vPXczWwzMA3LNrBz4LuAHcM497JzbZGYvA+uAEPCIc67baZOny7xJ4WGf17dUMmVEZoyrERE5vXoNd+fcgj60+THw46hUFCX5GcmcPTKLVzdVcPel42JdjojIaZVwZ6ge7dKJ+azeU8uhpvZYlyIicloldLjPn5SPc7Bka8yn3ouInFYJHe7TC7PITU/i1U0KdxEZXBI63D0e49KJeSzdWkVHMBTrckRETpuEDncID83Ut3aySjfOFpFBJOHD/aLxuQR8Hl5atz/WpYiInDYJH+4ZyX6umlbAH1bvpbldN/AQkcEh4cMd4NbzRtPQ1smLa9V7F5HBYVCE++ziHMblp/PEO7tjXYqIyGkxKMLdzLh1ThFr99Ty3r66WJcjIjLgBkW4A3x81kiSfB5+u0K9dxFJfIMm3LNS/Vx99nD+uGYfTW06sCoiiW3QhDvAp84rorGtk0ff2hXrUkREBtSgCvdZRTl8ZPIwfvLKVr759FpaO4KxLklEZEAMqnA3M/7nM+fypfnjeKq0nI8/9DZ7a1tiXZaISNQNqnAH8HqMr390Io/eXsLug81869n1sS5JRCTqBl24H/bhycP4wiVjWbq1ip1VjbEuR0QkqgZtuAPcMmcUfq/xm+WaHikiiaXXcDezx8ys0sy6vC+qmc0zszozWxP5+j/RL3Ng5Gckc9X04fx+1R5NjxSRhNKXnvsi4Ipe2rzpnJsZ+freqZd1+tw2dzQNrZ38Yc3eWJciIhI1vYa7c24pcOg01BITs4pymDoik8ffLsM5F+tyRESiIlpj7nPNbK2Z/dnMpkZpmaeFmXH73GK2VDSwYlfCvoeJyCATjXB/FxjtnJsB/D/gD901NLO7zKzUzEqrqqqisOrouHbmCLJS/Pz4f7foxCYRSQinHO7OuXrnXGPk+z8BfjPL7abtQudciXOuJC8v71RXHTXJfi//dv003t1dw91PvKv7rYpI3DvlcDezAjOzyPdzIss8eKrLPd2unTGC718/jVc3V/K1p9YSDGn8XUTil6+3Bma2GJgH5JpZOfBdwA/gnHsYuAn4ezPrBFqAW1ycHpn81HnhmTP//ufNBLwefnjjdAK+QX0qgIjEqV7D3Tm3oJfXHwQejFpFMfbFD51FW0eI//7rVvbUNPPQp2YxND0p1mWJiJwUdUu78OWPjOf+W2aydk8t1/3sb2zaXx/rkkRETorCvRvXzSzkqb+bS0cwxLUPvsUP/rSJ+taOWJclItInCvcezBiVzUv/dDE3njOSX7y5k/n/+Qa/W7lbB1tF5IyncO9FbnoSP7rpbP5494UUDUnlnmfWc9X9b/L65kqd0SoiZyyFex+dPTKbZ/7+An526yxaO4PcuWgltyxczpKtVQp5ETnjWKyCqaSkxJWWlsZk3aeqvTPEb1eU8fM3dlDZ0MakggzuvnQc18wYEevSRCTBmdkq51xJb+3Uc++HgM/DHReO4c17LuU/bjqbYMjxpcWr+Y+XN6sXLyJnBIX7KUjyebm5ZBQvf+USFswp4udv7OC+FzYS0gFXEYmxXk9ikt55PcYPbphGasDLo2/toqmtk+/fMI0knzfWpYnIIKVwjxIz45+vnkxako8HXt3G2vJafnzTDGaMyo51aSIyCCnco8jM+NplE5g5KotvP7uBG37+N26bW0xhdgptnUHMjE/OHkWuLmcgIgNMs2UGSH1rBz94aRNPrtxzzPO56Un85OYZXDLhxEseL91axbefW8+Ns0bytcsmnK5SRSSO9HW2jMJ9gDW0dmBmJPk87Khq5J8Wr2ZrRSNfuHgMt8wpYvSQVEIOfvy/m/nFm7vISPLR0NbJD2+czoI5RbEuX0TOMAr3M1RrR5Dvv7SR3yzfDUDA6yEzxUd1YzufPr+Ie6+czN1PvMtb26v55R2zuWRCHjurGvnDmn0UDUnl47MKiVw+X0QGIYX7GW7LgQbW761jW0UDe2qauW5mIZdPLQDCvf1PPLyM8poWpgzP5J33P7i369yxQ/n3j09n9NC0Pq3HOUdTe5CK+lb21rSwt7aFkHMsmF2Ex6M3CZF4o3CPc/vrWrjpoWX4vOGDsB+fNZLXNlfyg5c20REK8e2rJvOZ80d32YvffbCZX7y5k6Xbqqisb6Oli/vCfv/6aXz6/NFHHlc2tPLAq9sIhiA71U9eehIL5hSREtB0TpEzicI9AXQGQ3g9dkyAH6hr5VvPruP1LVUsmFPE966bit8bPhdtXXktC5fu5E/r9+PzeJg/KZ+ROSnkZSSRn5lEYXYqhTkp3PP0OtbsqeUvX72EEdkptHeGuPUXy1lbXktWip+6lg46go4HFpzDtbqkgsgZpa/hrqmQZzCf98QTiAuyknn09tn81ytb+NnrO3i/uolPzh7Fr5eXsaqshowkH1+4ZCyfvXAMwzKTu1zuD2+czkf/eynfeW49j90xm//70kZKy2qOhHlDawfT//Uv7K9tGehNFJEBonCPQx6P8Y3LJ3FWXjr3PrOeZTsPUjQklf/zsSl8omQkGcn+Hn9+1JBUvnH5RL734ka+tHg1L67bz+cvGnOkl56R7Cct4OVAfevp2BwRGQB9uUH2Y8DHgErn3LQe2s0GlgOfdM49Hb0SpTs3zhrJhGEZVDW0ccmEPLwncYD09guKeXHdPl5ct5+5Y4dy75WTjnl9WFYyFQp3kbjVl577IsI3wH68uwZm5gV+BPxvdMqSvppWmNWvn/N6jJ/cPJOFb+7ka5dNOGEIqCAzmf11CneReNXrVSGdc0uBQ700+xLwDFAZjaLk9CjOTeMHN0zv8nIIBVnJVCjcReLWKV/y18wKgRuAh0+9HDlTFGQmU9nQpssXi8SpaFzP/afAPc65EydTH8fM7jKzUjMrraqqisKqZaAUZCXTGXJUN7XFuhQR6YdohHsJ8KSZvQ/cBPzczK7vqqFzbqFzrsQ5V5KXd+KFs+TMcXgaZUWdwl0kHp1yuDvnxjjnip1zxcDTwD845/5wypVJTA3PCof7/jrNdReJR32ZCrkYmAfkmlk58F3AD+Cc0zh7gio43HPXdEiRuNRruDvnFvR1Yc65O06pGjljDE1PwusxncgkEqd0g2zpktdj5GckcUBj7iJxSeEu3RqWmcyBeo25i8Qjhbt0a3hWMgd0IpNIXFK4S7eGZSZTUa9hGZF4pHCXbhVkJdPY1klDa0esSxGRk6Rwl25pOqRI/FK4S7cKIicyacaMSPxRuEu3DvfcNdddJP4o3KVbh3vuGpYRiT8Kd+lWst9LVopf15cRiUMKd+lReK67xtxF4o3CXXoUnuuuYRmReKNwlx4VZCbrgKpIHFK4S4+GZSVT3dhGRzAU61L65L19dTS1dZ7ycto7Q9Q16+QtiV+9XvJXBrfhWck4B5UNbRRmp8S6nB49t7qcr/5uLYXZKXz/+mlcOim/X8upbGjls4tWsuVAA9fMGMHnLhrD1BFZPf5MKOTYV9dCYXYKZtZtu5qmdjbtr2dLRQO7qpuYVpjF1dOHk5ak/4oSXfqLkh4dmete19pluFc3tvG7lXt4elU5I7KTufeKyUwf2XUQlh1sYl15HQGfh4DPQyjkONjUzsHGdtKSvNxcMopkv7dfdb69o5pvPr2Oc0fnUN/SwZ2LVnLNjBGclZfGhr31bD5Qz9QRmXz9oxOZMCwDCN9lavGK3YQcfKJkJKOHprG9spE7fvkOBxvbuW5mIX9av59n393LeWOGcMcFxVw2ZRg+7wcfePfXtfD70nKeKt1DeU043D86dRhXTC3g3NE5R9rWt3bwwF+3sejt9+mM3HQ82e/h8WVl3Pf8e1w7cwRf/cgE8iO/b5FTZc7F5u72JSUlrrS0NCbrlr7buK+eqx54k/tvmcl1MwuPPN/aEeS+FzbyzKpy2oMhzhszhG2VjRxqaue6mSP4wsVjmTw8E6/HqGvu4P5Xt/H4sg+CrSsjc1L456uncPnUYZgZLe1BdlY3suVAA1sqGqioa+WjUwu4bMow/EcF7LaKBm586G2GZSbzzBcvIDng4aE3dvCz17fTGXKMzU1jfH4Gf9teTWN7JzfMLCToHC+t20/IOcyMYMhx0bhcNuyrw+cxHrtjNmePzKaupYPfrdzN48vKKK9pYXhWMvMn5bO/rpXtlY3sqWnGObhw3FA+NCGPd3YdYum2ato7Q2Qm+7hkQh4Th2Xwq2Xvc7CpnZvPHcU1M0YwYVg6eRlJrCqr4cmVe3h+zT6uml7AT285ZwD3piQCM1vlnCvptZ3CXXrS3N7JJf/xBp2hEP/z6XM5b+xQ6po7+PzjKyktq+HT543m9guKGZefTkNrBw8v2cEjb+6irTNEWsDLjFHZbNpfT21LB58sGcVn5o7GOWgPhjAgNz2JoekB1uyp5b7nN7KlooEJw9Kpa+k45oqUfq+RkeznUFM7wzKTuOGckTgc+2pbWb7zIM7Bc/9wAaOGpB75mdrmdvxez5Ehj5qmdh5esoNFb79PwOvhk7NHcfsFxfi9Hp4q3cOT7+wmJeDll3fMoWho6jG/h2DI8eqmCn617H1W766laEgqZ+WnM7kgg2tnFB7TvrGtkyVbqnhjSyVvbK2iqqGNc0fn8K/XTO32U83XnlrDa5srKf3OR475ZCByvKiFu5k9BnwMqHTOTevi9euAfwNCQCfwFefcW72tWOEeP8oONnHnopXsOdTMt66czJMrd7Oruomf3DyTa2aMOKF9VUMbb++oZlVZDavKashNT+KbV0zsddy6MxjiN8vL+MvGCoZnpVA8NJXi3DQmFmQwJjcNjxlvbKnk8WVlLNlaRcDrYXh2MkVDUrnniklMK+x5+YfVt3bg8xipgWNHJZ1zhFz4LlTREgo5DtS3Mjwrucex+JfW7efu377L7784l9nFQ6K2fkk80Qz3S4BG4PFuwj0daHLOOTM7G3jKOTeptxUr3ONLXXMHX/zNKpbtPEh6ko+FnzmXC8blxqye5vZOkn1ePFEM4liqb+1g1vde4fMXj+XeK3v97yODWF/DvdfPf865pcChHl5vdB+8Q6QBsRnnkQGVlernV5+dwz9fPZmn/35uTIMdIDXgS5hgB8hM9jNnzBBe21wR61IkQURlcM/MbjCzzcBLwGejsUw58wR8Hj5/8VgmFWTGupSENH9SPlsrGtlzqDnWpUgCiEq4O+eeiwzFXE94/L1LZnaXmZWaWWlVVVU0Vi2SMOZH5uW/trkyxpVEV3N7J+9XNxHqYaZUXxxsbOPP6/fz5rYqdlY10toRjFKFiSmq89ydc0vN7Cwzy3XOVXfx+kJgIYTH3KO5bpF4NzYvnTG5aby6uZLbLyiOaS3tnSGeebec2cU5jMvP6NcynHO8vOEA//rCe1TUt5GV4mdWUTYXj8/j1vOKej2nwTnH9spGXt9SySsbK1hVVsPR7w9mMGV4JhePz+Oicblkp/ppD4bo6AxRmJPS6wllie6Uw93MxgE7IgdUZwEB4OApVyYyCM2flM+vl5XR1NbZ5VmrwZDjnV2H+NP6/bx/sIn0JB/pST4KspI5f+xQzh2d02NoVta38ucNBygtq2HmqGw+PCmf4ty0Y9psOdDAV3+3ho376/F7jb+75Cz+cf44kv1emto6WVdeR2F2ygnTRSvqWyk72ExnMERbMMQTy8v466ZKpgzP5O5Lx7FxXz2lZTV878WN/PLtXXznqg/OaTjaxn31/Hp5GUu2VLKvLnxdo8nDM/nH+eOZNzGP9s4Qe2taKDvYxPKdh3jkzZ08vGTHCds6LDOJWUU5jM1LY0haEkPTAozLT2fK8MyEOl7Tnb7MllkMzANygQrgu4AfwDn3sJndA9wGdAAtwDc0FVKkf97eXs2tj6zgvmunMiI7hbKDTVQ2tFHX3EFNczvv7q6lurGNZL+HicMyaG4P0tTWSUVDG8GQI8nnYVx+Oi3tQepbO2nvDDI0PYm89CRCzrFqdw3OQW56gOrGdgDG5KYxqSCD0UPT8Bg88tYuMpJ8/MvHprB0axXPrt5L0ZBUclL9bNhXTzDSfb5w3FBumV1EW2eI51aX8/aO8PkGh6X4vXztsgnceWHxMXP3/7a9mvteeI+tFY2UjM7hQxPyOHd0Dkl+Lw8v2cErGytIC3i5eHweH5qYxyUT8nq89EVjWyerympo7QgS8HnwezzsrG5kVVkNq3fXsre25UjNEN72w58e4nHaqU5iEolD7Z0hzv3+KzS0fnDxsySfh+xUP9kpAc7KT+Oq6cOZPyn/mHn6jW2dvLPrIH/bfpCdVY2kJfnISPbj9xoHm9qpbmijtTPEvAl5XH32cCYMy6DsYBOvba7krW3V7KpuYk9NMx1Bx2VThvHDG6eTm54EhC/t8KOXt5Dk9TBnzBBmjc7mvb31PLlyD3trwzdyKRqSyvXnFDK7OAe/14Pfa4wemnZkGcfrDIZ4YsVunlhRxtaKxiPPZyb7+NxFY7njwmKyUvxR+Z2GQo761g6qG9tZV17Lkq1VLN1aRUtHkD/efRETC/o37BQrCneROLXy/UPsq21h9NA0ioemkp0aOC3rDYYctc3tDEkL9GmsOhhyrNh1kCSfl1lF2f0e365r7mD1nhoq69u4cnoBGcnRCfWeVDa0ctX9b5GV4uP5f7zopC7c1hEMUXawmcLsFFIC/bsW0qlQuIuI9ODt7dV86tEV3DCzkP+6ecYJb06dwRBlh5rpDDqCIcf+uhZe3nCAVzZVUNvcgVn4ekjj8tKPvBGPyUtn7tihBHwfDEPtrW1h4ZIdNLcHyU71k5XiZ3bxEM4bO7Rfdfc13HVVSBEZlC4Yl8uXPzyen/51G2Ny05g/OZ+iIakcbGznqdLwlU4rG469xWRGko8PT87ngrNywxePq2pke2UjK3Ydork9PDVzeFYyn7toDB+fNZLfvrObB1/bTtA5hqQGqG1pp7UjxN2XntXvcO8r9dxFZNAKhhx3LlrJ0q3HnnfjMbh0Yj6XTysgLeDD6zEyk32cW5xDku/EoRjnHNWN7azdU8sjb+1k+c5DmIFzcMXUAr5z9eQjF7Vr6wwSCtHvIR0Ny4iI9EFnMMTmAw3sOdRM2aFmPAbXziikIKv/19Z/d3cNL6zdx7yJ+XxoQl4Uq9WwjIhIn/i8HqYVZvX5qqJ9Masoh1lFOVFbXn/owtEiIglI4S4ikoAU7iIiCUjhLiKSgBTuIiIJSOEuIpKAFO4iIglI4S4ikoBidoaqmVUBZf388VzghDs9DQKDcbsH4zbD4NzuwbjNcPLbPdo51+tprzEL91NhZqV9Of020QzG7R6M2wyDc7sH4zbDwG23hmVERBKQwl1EJAHFa7gvjHUBMTIYt3swbjMMzu0ejNsMA7TdcTnmLiIiPYvXnruIiPQg7sLdzK6Prs+JAAADj0lEQVQwsy1mtt3M7o11PQPBzEaZ2etmtsnM3jOzL0eeH2Jmr5jZtsi/sb1g9AAxM6+ZrTazFyOPx5jZish2/87MTs8do08TM8s2s6fNbHNkn88dDPvazL4a+fveYGaLzSw5Efe1mT1mZpVmtuGo57rcvxb2QCTf1pnZrP6uN67C3cy8wM+AK4EpwAIzmxLbqgZEJ/B159xk4Hzg7sh23gu86pwbD7waeZyIvgxsOurxj4D/jmx3DfC5mFQ1cO4HXnbOTQJmEN72hN7XZlYI/BNQ4pybBniBW0jMfb0IuOK457rbv1cC4yNfdwEP9XelcRXuwBxgu3Nup3OuHXgSuC7GNUWdc26/c+7dyPcNhP+zFxLe1l9Fmv0KuD42FQ4cMxsJXA08EnlswHzg6UiThNpuM8sELgEeBXDOtTvnahkE+5rwneBSzMwHpAL7ScB97ZxbChw67unu9u91wOMubDmQbWbD+7PeeAv3QmDPUY/LI88lLDMrBs4BVgDDnHP7IfwGAOTHrrIB81Pgm0Ao8ngoUOuc64w8TrR9PhaoAn4ZGYp6xMzSSPB97ZzbC/wnsJtwqNcBq0jsfX207vZv1DIu3sLdunguYaf7mFk68AzwFedcfazrGWhm9jGg0jm36uinu2iaSPvcB8wCHnLOnQM0kWBDMF2JjDFfB4wBRgBphIckjpdI+7ovovb3Hm/hXg6MOurxSGBfjGoZUGbmJxzsTzjnno08XXH4I1rk38pY1TdALgSuNbP3CQ+5zSfck8+OfHSHxNvn5UC5c25F5PHThMM+0ff1R4Bdzrkq51wH8CxwAYm9r4/W3f6NWsbFW7ivBMZHjqgHCB+AeT7GNUVdZJz5UWCTc+4nR730PHB75PvbgT+e7toGknPuW865kc65YsL79jXn3KeA14GbIs0SarudcweAPWY2MfLUh4GNJPi+Jjwcc76ZpUb+3g9vd8Lu6+N0t3+fB26LzJo5H6g7PHxz0pxzcfUFXAVsBXYA34l1PQO0jRcR/ii2DlgT+bqK8Pjzq8C2yL9DYl3rAP4O5gEvRr4fC7wDbAd+DyTFur4ob+tMoDSyv/8A5AyGfQ3cB2wGNgC/BpIScV8DiwkfV+gg3DP/XHf7l/CwzM8i+bae8Gyifq1XZ6iKiCSgeBuWERGRPlC4i4gkIIW7iEgCUriLiCQghbuISAJSuIuIJCCFu4hIAlK4i4gkoP8PW6Rzsnjh1A8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9dfc639fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net3 = rand_Net3()\n",
    "net3.cuda()\n",
    "train_eval(net3,n_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net3u(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3u, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net3u = rand_Net3u()\n",
    "net3u.cuda()\n",
    "train_eval(net3u,n_epochs=130)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with different random init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net3_lap(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3_lap, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 512, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        for k in range(self.conv1.weight.data.shape[1]):\n",
    "            self.conv1.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        for k in range(self.conv2.weight.data.shape[1]):\n",
    "            self.conv2.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        for k in range(self.conv3.weight.data.shape[1]):\n",
    "            self.conv3.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.120\n",
      "[2,  2000] loss: 1.803\n",
      "[3,  2000] loss: 1.709\n",
      "[4,  2000] loss: 1.659\n",
      "[5,  2000] loss: 1.622\n",
      "[6,  2000] loss: 1.594\n",
      "[7,  2000] loss: 1.566\n",
      "[8,  2000] loss: 1.558\n",
      "[9,  2000] loss: 1.542\n",
      "[10,  2000] loss: 1.535\n",
      "[11,  2000] loss: 1.530\n",
      "[12,  2000] loss: 1.509\n",
      "[13,  2000] loss: 1.513\n",
      "[14,  2000] loss: 1.498\n",
      "[15,  2000] loss: 1.501\n",
      "[16,  2000] loss: 1.489\n",
      "[17,  2000] loss: 1.497\n",
      "[18,  2000] loss: 1.490\n",
      "[19,  2000] loss: 1.490\n",
      "[20,  2000] loss: 1.473\n",
      "[21,  2000] loss: 1.482\n",
      "[22,  2000] loss: 1.490\n",
      "[23,  2000] loss: 1.470\n",
      "[24,  2000] loss: 1.490\n",
      "[25,  2000] loss: 1.480\n",
      "[26,  2000] loss: 1.470\n",
      "[27,  2000] loss: 1.475\n",
      "[28,  2000] loss: 1.469\n",
      "[29,  2000] loss: 1.470\n",
      "[30,  2000] loss: 1.471\n",
      "[31,  2000] loss: 1.325\n",
      "[32,  2000] loss: 1.318\n",
      "[33,  2000] loss: 1.314\n",
      "[34,  2000] loss: 1.317\n",
      "[35,  2000] loss: 1.325\n",
      "[36,  2000] loss: 1.320\n",
      "[37,  2000] loss: 1.324\n",
      "[38,  2000] loss: 1.324\n",
      "[39,  2000] loss: 1.324\n",
      "[40,  2000] loss: 1.320\n",
      "[41,  2000] loss: 1.320\n",
      "[42,  2000] loss: 1.327\n",
      "[43,  2000] loss: 1.318\n",
      "[44,  2000] loss: 1.320\n",
      "[45,  2000] loss: 1.318\n",
      "[46,  2000] loss: 1.320\n",
      "[47,  2000] loss: 1.326\n",
      "[48,  2000] loss: 1.321\n",
      "[49,  2000] loss: 1.318\n",
      "[50,  2000] loss: 1.323\n",
      "[51,  2000] loss: 1.321\n",
      "[52,  2000] loss: 1.317\n",
      "[53,  2000] loss: 1.325\n",
      "[54,  2000] loss: 1.323\n",
      "[55,  2000] loss: 1.321\n",
      "[56,  2000] loss: 1.318\n",
      "[57,  2000] loss: 1.328\n",
      "[58,  2000] loss: 1.321\n",
      "[59,  2000] loss: 1.327\n",
      "[60,  2000] loss: 1.318\n",
      "[61,  2000] loss: 1.277\n",
      "[62,  2000] loss: 1.278\n",
      "[63,  2000] loss: 1.279\n",
      "[64,  2000] loss: 1.281\n",
      "[65,  2000] loss: 1.279\n",
      "[66,  2000] loss: 1.282\n",
      "[67,  2000] loss: 1.276\n",
      "[68,  2000] loss: 1.285\n",
      "[69,  2000] loss: 1.275\n",
      "[70,  2000] loss: 1.288\n",
      "[71,  2000] loss: 1.276\n",
      "[72,  2000] loss: 1.281\n",
      "[73,  2000] loss: 1.281\n",
      "[74,  2000] loss: 1.284\n",
      "[75,  2000] loss: 1.280\n",
      "[76,  2000] loss: 1.280\n",
      "[77,  2000] loss: 1.277\n",
      "[78,  2000] loss: 1.284\n",
      "[79,  2000] loss: 1.280\n",
      "[80,  2000] loss: 1.274\n",
      "[81,  2000] loss: 1.284\n",
      "[82,  2000] loss: 1.281\n",
      "[83,  2000] loss: 1.279\n",
      "[84,  2000] loss: 1.281\n",
      "[85,  2000] loss: 1.285\n",
      "[86,  2000] loss: 1.285\n",
      "[87,  2000] loss: 1.279\n",
      "[88,  2000] loss: 1.279\n",
      "[89,  2000] loss: 1.273\n",
      "[90,  2000] loss: 1.282\n",
      "[91,  2000] loss: 1.264\n",
      "[92,  2000] loss: 1.261\n",
      "[93,  2000] loss: 1.263\n",
      "[94,  2000] loss: 1.261\n",
      "[95,  2000] loss: 1.261\n",
      "[96,  2000] loss: 1.263\n",
      "[97,  2000] loss: 1.257\n",
      "[98,  2000] loss: 1.264\n",
      "[99,  2000] loss: 1.268\n",
      "[100,  2000] loss: 1.267\n",
      "[101,  2000] loss: 1.264\n",
      "[102,  2000] loss: 1.263\n",
      "[103,  2000] loss: 1.269\n",
      "[104,  2000] loss: 1.262\n",
      "[105,  2000] loss: 1.262\n",
      "[106,  2000] loss: 1.261\n",
      "[107,  2000] loss: 1.259\n",
      "[108,  2000] loss: 1.267\n",
      "[109,  2000] loss: 1.265\n"
     ]
    }
   ],
   "source": [
    "net3l = rand_Net3_lap()\n",
    "net3l.cuda()\n",
    "train_eval(net3l,n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  0.]]\n",
      "[[ 0.  0.  0.]\n",
      " [ 1. -1. -1.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "H = np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3)))\n",
    "H = np.matmul(np.random.choice([-1.,0,1.],(3,1)),np.random.choice([-1.,0,1.],(1,3)))\n",
    "print H\n",
    "#print H/np.max((np.ones(3),np.sqrt(H.sum(0))))\n",
    "\n",
    "\n",
    "\n",
    "print preprocessing.normalize(H, norm='l2', axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net3_haar(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3_haar, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 256, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(256, 256, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        for k in range(self.conv1.weight.data.shape[1]):\n",
    "            H = np.matmul(np.random.choice([-1.,0,1.],(3,1)),np.random.choice([-1.,0,1.],(1,3)))\n",
    "            #self.conv1.weight.data[k,0,:,:] = torch.FloatTensor(preprocessing.normalize(H, norm='l2', axis=0))\n",
    "        for k in range(self.conv2.weight.data.shape[1]):\n",
    "            H = np.matmul(np.random.choice([-1.,0,1.],(3,1)),np.random.choice([-1.,0,1.],(1,3)))\n",
    "            #self.conv2.weight.data[k,0,:,:] = torch.FloatTensor(preprocessing.normalize(H, norm='l2', axis=0))\n",
    "        for k in range(self.conv3.weight.data.shape[1]):\n",
    "            H = np.matmul(np.random.choice([-1.,0,1.],(3,1)),np.random.choice([-1.,0,1.],(1,3)))\n",
    "            #self.conv3.weight.data[k,0,:,:] = torch.FloatTensor(preprocessing.normalize(H, norm='l2', axis=0))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.909\n",
      "[2,  2000] loss: 1.687\n",
      "[3,  2000] loss: 1.617\n",
      "[4,  2000] loss: 1.568\n",
      "[5,  2000] loss: 1.541\n",
      "[6,  2000] loss: 1.516\n",
      "[7,  2000] loss: 1.500\n",
      "[8,  2000] loss: 1.484\n",
      "[9,  2000] loss: 1.473\n",
      "[10,  2000] loss: 1.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-25:\n",
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 378, in get\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "    return recv()\n",
      "    racquire()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c229590667b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet3h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_Net3_haar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet3h\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-884394d9df9d>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(net, n_epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m#optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001, momentum=0.9)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ca65a54c0aee>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yuki/anaconda2/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mmax_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0mSee\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m`\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdetails\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \"\"\"\n\u001b[0;32m--> 334\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net3h = rand_Net3_haar()\n",
    "train_eval(net3h,n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class rand_Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32*2, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32*2, 64*2, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64*2, 128*2, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128*2, 512*2, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(2048*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),kernel_size=2, stride=2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.099\n",
      "[2,  2000] loss: 1.878\n",
      "[3,  2000] loss: 1.801\n",
      "[4,  2000] loss: 1.762\n",
      "[5,  2000] loss: 1.728\n",
      "[6,  2000] loss: 1.706\n",
      "[7,  2000] loss: 1.688\n",
      "[8,  2000] loss: 1.683\n",
      "[9,  2000] loss: 1.669\n",
      "[10,  2000] loss: 1.660\n",
      "[11,  2000] loss: 1.652\n",
      "[12,  2000] loss: 1.644\n",
      "[13,  2000] loss: 1.637\n",
      "[14,  2000] loss: 1.629\n",
      "[15,  2000] loss: 1.626\n",
      "[16,  2000] loss: 1.626\n",
      "[17,  2000] loss: 1.621\n",
      "[18,  2000] loss: 1.619\n",
      "[19,  2000] loss: 1.615\n",
      "[20,  2000] loss: 1.613\n",
      "[21,  2000] loss: 1.617\n",
      "[22,  2000] loss: 1.611\n",
      "[23,  2000] loss: 1.611\n",
      "[24,  2000] loss: 1.603\n",
      "[25,  2000] loss: 1.606\n",
      "[26,  2000] loss: 1.608\n",
      "[27,  2000] loss: 1.604\n",
      "[28,  2000] loss: 1.604\n",
      "[29,  2000] loss: 1.606\n",
      "[30,  2000] loss: 1.604\n",
      "[31,  2000] loss: 1.592\n",
      "[32,  2000] loss: 1.594\n",
      "[33,  2000] loss: 1.594\n",
      "[34,  2000] loss: 1.586\n",
      "[35,  2000] loss: 1.595\n",
      "[36,  2000] loss: 1.591\n",
      "[37,  2000] loss: 1.590\n",
      "[38,  2000] loss: 1.590\n",
      "[39,  2000] loss: 1.595\n",
      "[40,  2000] loss: 1.590\n",
      "[41,  2000] loss: 1.593\n",
      "[42,  2000] loss: 1.589\n",
      "[43,  2000] loss: 1.597\n",
      "[44,  2000] loss: 1.594\n",
      "[45,  2000] loss: 1.591\n",
      "[46,  2000] loss: 1.585\n",
      "[47,  2000] loss: 1.593\n",
      "[48,  2000] loss: 1.589\n",
      "[49,  2000] loss: 1.594\n",
      "[50,  2000] loss: 1.589\n",
      "[51,  2000] loss: 1.591\n",
      "[52,  2000] loss: 1.589\n",
      "[53,  2000] loss: 1.588\n",
      "[54,  2000] loss: 1.586\n",
      "[55,  2000] loss: 1.586\n",
      "[56,  2000] loss: 1.592\n",
      "[57,  2000] loss: 1.592\n",
      "[58,  2000] loss: 1.592\n",
      "[59,  2000] loss: 1.590\n",
      "[60,  2000] loss: 1.587\n",
      "[61,  2000] loss: 1.582\n",
      "[62,  2000] loss: 1.583\n",
      "[63,  2000] loss: 1.581\n",
      "[64,  2000] loss: 1.588\n",
      "[65,  2000] loss: 1.590\n",
      "[66,  2000] loss: 1.584\n",
      "[67,  2000] loss: 1.582\n",
      "[68,  2000] loss: 1.589\n",
      "[69,  2000] loss: 1.584\n",
      "[70,  2000] loss: 1.586\n",
      "[71,  2000] loss: 1.578\n",
      "[72,  2000] loss: 1.586\n",
      "[73,  2000] loss: 1.585\n",
      "[74,  2000] loss: 1.583\n",
      "[75,  2000] loss: 1.586\n",
      "[76,  2000] loss: 1.584\n",
      "[77,  2000] loss: 1.585\n",
      "[78,  2000] loss: 1.592\n",
      "[79,  2000] loss: 1.585\n",
      "[80,  2000] loss: 1.581\n",
      "[81,  2000] loss: 1.588\n",
      "[82,  2000] loss: 1.585\n",
      "[83,  2000] loss: 1.584\n",
      "[84,  2000] loss: 1.582\n",
      "[85,  2000] loss: 1.582\n",
      "[86,  2000] loss: 1.588\n",
      "[87,  2000] loss: 1.583\n",
      "[88,  2000] loss: 1.585\n",
      "[89,  2000] loss: 1.583\n",
      "[90,  2000] loss: 1.582\n",
      "[91,  2000] loss: 1.583\n",
      "[92,  2000] loss: 1.584\n",
      "[93,  2000] loss: 1.584\n",
      "[94,  2000] loss: 1.584\n",
      "[95,  2000] loss: 1.584\n",
      "[96,  2000] loss: 1.585\n",
      "[97,  2000] loss: 1.585\n",
      "[98,  2000] loss: 1.583\n",
      "[99,  2000] loss: 1.580\n",
      "[100,  2000] loss: 1.578\n",
      "[101,  2000] loss: 1.582\n",
      "[102,  2000] loss: 1.583\n",
      "[103,  2000] loss: 1.584\n",
      "[104,  2000] loss: 1.583\n",
      "[105,  2000] loss: 1.581\n",
      "[106,  2000] loss: 1.585\n",
      "[107,  2000] loss: 1.584\n",
      "[108,  2000] loss: 1.583\n",
      "[109,  2000] loss: 1.578\n",
      "[110,  2000] loss: 1.585\n",
      "[111,  2000] loss: 1.583\n",
      "[112,  2000] loss: 1.579\n",
      "[113,  2000] loss: 1.585\n",
      "[114,  2000] loss: 1.579\n",
      "[115,  2000] loss: 1.583\n",
      "[116,  2000] loss: 1.582\n",
      "[117,  2000] loss: 1.584\n",
      "[118,  2000] loss: 1.582\n",
      "[119,  2000] loss: 1.585\n",
      "[120,  2000] loss: 1.583\n",
      "[121,  2000] loss: 1.580\n",
      "[122,  2000] loss: 1.576\n",
      "[123,  2000] loss: 1.578\n",
      "[124,  2000] loss: 1.580\n",
      "[125,  2000] loss: 1.579\n",
      "[126,  2000] loss: 1.585\n",
      "[127,  2000] loss: 1.577\n",
      "[128,  2000] loss: 1.580\n",
      "[129,  2000] loss: 1.579\n",
      "[130,  2000] loss: 1.576\n",
      "[131,  2000] loss: 1.584\n",
      "[132,  2000] loss: 1.579\n",
      "[133,  2000] loss: 1.579\n",
      "[134,  2000] loss: 1.581\n",
      "[135,  2000] loss: 1.580\n",
      "[136,  2000] loss: 1.580\n",
      "[137,  2000] loss: 1.585\n",
      "[138,  2000] loss: 1.581\n",
      "[139,  2000] loss: 1.578\n",
      "[140,  2000] loss: 1.580\n",
      "[141,  2000] loss: 1.584\n",
      "[142,  2000] loss: 1.579\n",
      "[143,  2000] loss: 1.582\n",
      "[144,  2000] loss: 1.586\n",
      "[145,  2000] loss: 1.583\n",
      "[146,  2000] loss: 1.584\n",
      "[147,  2000] loss: 1.580\n",
      "[148,  2000] loss: 1.584\n",
      "[149,  2000] loss: 1.578\n",
      "[150,  2000] loss: 1.582\n",
      "[151,  2000] loss: 1.581\n",
      "[152,  2000] loss: 1.578\n",
      "[153,  2000] loss: 1.578\n",
      "[154,  2000] loss: 1.581\n",
      "[155,  2000] loss: 1.577\n",
      "[156,  2000] loss: 1.580\n",
      "[157,  2000] loss: 1.578\n",
      "[158,  2000] loss: 1.578\n",
      "[159,  2000] loss: 1.582\n",
      "[160,  2000] loss: 1.583\n",
      "[161,  2000] loss: 1.581\n",
      "[162,  2000] loss: 1.576\n",
      "[163,  2000] loss: 1.579\n",
      "[164,  2000] loss: 1.581\n",
      "[165,  2000] loss: 1.580\n",
      "[166,  2000] loss: 1.581\n",
      "[167,  2000] loss: 1.582\n",
      "[168,  2000] loss: 1.580\n",
      "[169,  2000] loss: 1.581\n",
      "[170,  2000] loss: 1.583\n",
      "[171,  2000] loss: 1.583\n",
      "[172,  2000] loss: 1.579\n",
      "[173,  2000] loss: 1.583\n",
      "[174,  2000] loss: 1.582\n",
      "[175,  2000] loss: 1.580\n",
      "[176,  2000] loss: 1.574\n",
      "[177,  2000] loss: 1.581\n",
      "[178,  2000] loss: 1.588\n",
      "[179,  2000] loss: 1.577\n",
      "[180,  2000] loss: 1.579\n",
      "[181,  2000] loss: 1.579\n",
      "[182,  2000] loss: 1.577\n",
      "[183,  2000] loss: 1.581\n",
      "[184,  2000] loss: 1.581\n",
      "[185,  2000] loss: 1.581\n",
      "[186,  2000] loss: 1.580\n",
      "[187,  2000] loss: 1.577\n",
      "[188,  2000] loss: 1.583\n",
      "[189,  2000] loss: 1.580\n",
      "[190,  2000] loss: 1.581\n",
      "[191,  2000] loss: 1.576\n",
      "[192,  2000] loss: 1.576\n",
      "[193,  2000] loss: 1.577\n",
      "[194,  2000] loss: 1.583\n",
      "[195,  2000] loss: 1.580\n",
      "[196,  2000] loss: 1.582\n",
      "[197,  2000] loss: 1.579\n",
      "[198,  2000] loss: 1.578\n",
      "[199,  2000] loss: 1.582\n",
      "[200,  2000] loss: 1.578\n",
      "Finished Training\n",
      "Accuracy of plane : 62 %\n",
      "Accuracy of   car : 51 %\n",
      "Accuracy of  bird : 31 %\n",
      "Accuracy of   cat : 23 %\n",
      "Accuracy of  deer : 41 %\n",
      "Accuracy of   dog : 54 %\n",
      "Accuracy of  frog : 56 %\n",
      "Accuracy of horse : 56 %\n",
      "Accuracy of  ship : 61 %\n",
      "Accuracy of truck : 54 %\n",
      "0.4924\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9dfc4f3e50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net4 = rand_Net4()\n",
    "net4.cuda()\n",
    "train_eval(net4,n_epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vgg11 [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "   \n",
    "class rand_vgg11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_vgg11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128*2, 3,padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128*2, 256*2, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(256*2, 256*2, 3,padding=1)\n",
    "                \n",
    "        self.conv5 = nn.Conv2d(256*2, 512*4, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(512*4, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv5.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv6.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv7.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv8.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv6(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv8(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netvgg11 = rand_vgg11()\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "losses=[]\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, fcw = netvgg11(inputs)\n",
    "                \n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, netvgg11.parameters()), lr=0.001, momentum=0.9)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #l1 = torch.abs(fcw).sum()\n",
    "        #print('CRIT', criterion(outputs, labels))\n",
    "        #print('L1', l1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) #+ 0.001*l1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    losses.append(loss.data[0])\n",
    "plt.plot(losses)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane :  0 %\n",
      "Accuracy of   car :  0 %\n",
      "Accuracy of  bird :  0 %\n",
      "Accuracy of   cat :  0 %\n",
      "Accuracy of  deer : 100 %\n",
      "Accuracy of   dog :  0 %\n",
      "Accuracy of  frog :  0 %\n",
      "Accuracy of horse :  0 %\n",
      "Accuracy of  ship :  0 %\n",
      "Accuracy of truck :  0 %\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs,_ = netvgg11(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(8):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to pixel by pixel Lasso classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=7000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=500,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute purely on pixels\n",
      "1\n",
      "-----\n",
      "Accuracy of plane : 43 %\n",
      "Accuracy of   car : 43 %\n",
      "Accuracy of  bird : 26 %\n",
      "Accuracy of   cat : 17 %\n",
      "Accuracy of  deer : 28 %\n",
      "Accuracy of   dog : 27 %\n",
      "Accuracy of  frog : 48 %\n",
      "Accuracy of horse : 48 %\n",
      "Accuracy of  ship : 53 %\n",
      "Accuracy of truck : 41 %\n",
      "0.3804\n",
      "-----\n",
      "Accuracy of plane : 46 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 33 %\n",
      "Accuracy of   cat : 21 %\n",
      "Accuracy of  deer : 32 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 51 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 66 %\n",
      "Accuracy of truck : 51 %\n",
      "0.4368\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics,preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('compute purely on pixels')\n",
    "for ty,data in enumerate(trainloader):\n",
    "    images, labels = data\n",
    "    for alpha in [1]:#np.logspace(0,3,10):\n",
    "        print alpha\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=3)\n",
    "        rf = RandomForestClassifier(n_estimators = 300,n_jobs=6)\n",
    "        reg.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "        rf.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "    for mod in [reg,rf]:\n",
    "        print (\"-----\")\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        for a,data in enumerate(testloader):\n",
    "            imagesp, labelsp = data\n",
    "            predicted = mod.predict(imagesp[:,:,:,:].numpy().reshape(500,-1))\n",
    "            c = (predicted == labelsp).squeeze()\n",
    "            for i in range(500):\n",
    "                label = labelsp[i]\n",
    "                class_correct[label] += c[i]\n",
    "                class_total[label] += 1\n",
    "            if a>=4:\n",
    "                break \n",
    "        for i in range(10):\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print np.sum(class_correct)/np.sum(class_total)\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
