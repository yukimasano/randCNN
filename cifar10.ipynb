{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=8,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3,1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3,1 )\n",
    "        self.conv3 = nn.Conv2d(64, 256, 3,1 )\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "        self.conv1.train(False)\n",
    "        self.conv2.train(False)\n",
    "        self.conv3.train(False)\n",
    "\n",
    "        #for k in range(self.conv1.weight.data.shape[1]):\n",
    "        #    self.conv1.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.random(-1.,1.,(5,1)),np.random.random(-1.,1.,(1,5))))\n",
    "        #for k in range(self.conv2.weight.data.shape[1]):\n",
    "        #    self.conv2.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.random(-1.,1.,(5,1)),np.random.random(-1.,1.,(1,5))))\n",
    "        #for k in range(self.conv3.weight.data.shape[1]):\n",
    "        #    self.conv3.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.random((5,1)),np.random.random((1,5))))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x),kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),kernel_size=2, stride=2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, x\n",
    "    \n",
    "class rand_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        #x = F.relu(F.max_pool2d(self.conv3(x), 2))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.301\n",
      "[1,  4000] loss: 2.289\n",
      "[1,  6000] loss: 2.270\n",
      "[2,  2000] loss: 2.237\n",
      "[2,  4000] loss: 2.206\n",
      "[2,  6000] loss: 2.176\n",
      "[3,  2000] loss: 2.143\n",
      "[3,  4000] loss: 2.118\n",
      "[3,  6000] loss: 2.080\n",
      "[4,  2000] loss: 2.048\n",
      "[4,  4000] loss: 2.010\n",
      "[4,  6000] loss: 1.985\n",
      "[5,  2000] loss: 1.947\n",
      "[5,  4000] loss: 1.934\n",
      "[5,  6000] loss: 1.916\n",
      "[6,  2000] loss: 1.882\n",
      "[6,  4000] loss: 1.879\n",
      "[6,  6000] loss: 1.860\n",
      "[7,  2000] loss: 1.834\n",
      "[7,  4000] loss: 1.827\n",
      "[7,  6000] loss: 1.805\n",
      "[8,  2000] loss: 1.798\n",
      "[8,  4000] loss: 1.767\n",
      "[8,  6000] loss: 1.768\n",
      "[9,  2000] loss: 1.744\n",
      "[9,  4000] loss: 1.739\n",
      "[9,  6000] loss: 1.724\n",
      "[10,  2000] loss: 1.709\n",
      "[10,  4000] loss: 1.687\n",
      "[10,  6000] loss: 1.694\n",
      "[11,  2000] loss: 1.670\n",
      "[11,  4000] loss: 1.664\n",
      "[11,  6000] loss: 1.652\n",
      "[12,  2000] loss: 1.641\n",
      "[12,  4000] loss: 1.631\n",
      "[12,  6000] loss: 1.615\n",
      "[13,  2000] loss: 1.603\n",
      "[13,  4000] loss: 1.606\n",
      "[13,  6000] loss: 1.588\n",
      "[14,  2000] loss: 1.574\n",
      "[14,  4000] loss: 1.572\n",
      "[14,  6000] loss: 1.561\n",
      "[15,  2000] loss: 1.551\n",
      "[15,  4000] loss: 1.549\n",
      "[15,  6000] loss: 1.529\n",
      "[16,  2000] loss: 1.530\n",
      "[16,  4000] loss: 1.509\n",
      "[16,  6000] loss: 1.511\n",
      "[17,  2000] loss: 1.501\n",
      "[17,  4000] loss: 1.498\n",
      "[17,  6000] loss: 1.480\n",
      "[18,  2000] loss: 1.481\n",
      "[18,  4000] loss: 1.464\n",
      "[18,  6000] loss: 1.468\n",
      "[19,  2000] loss: 1.456\n",
      "[19,  4000] loss: 1.451\n",
      "[19,  6000] loss: 1.444\n",
      "[20,  2000] loss: 1.441\n",
      "[20,  4000] loss: 1.435\n",
      "[20,  6000] loss: 1.418\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = rand_Net3()\n",
    "for epoch in range(20):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, fcw = net(inputs)\n",
    "        l1 = torch.abs(fcw).sum()\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss() \n",
    "        optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print('CRIT', criterion(outputs, labels))\n",
    "        #print('L1', l1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) + 0.005*l1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs,_ = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(8):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute purely on pixels\n",
      "1\n",
      "-----\n",
      "Accuracy of plane : 44 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat : 19 %\n",
      "Accuracy of  deer : 30 %\n",
      "Accuracy of   dog : 30 %\n",
      "Accuracy of  frog : 53 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 50 %\n",
      "Accuracy of truck : 38 %\n",
      "0.3828\n",
      "-----\n",
      "Accuracy of plane : 44 %\n",
      "Accuracy of   car : 47 %\n",
      "Accuracy of  bird : 29 %\n",
      "Accuracy of   cat : 16 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 40 %\n",
      "Accuracy of  frog : 59 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 64 %\n",
      "Accuracy of truck : 56 %\n",
      "0.4408\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics,preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('compute purely on pixels')\n",
    "for ty,data in enumerate(trainloader):\n",
    "    images, labels = data\n",
    "    for alpha in [1]:#np.logspace(0,3,10):\n",
    "        print alpha\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=3)\n",
    "        rf = RandomForestClassifier(n_estimators = 500,n_jobs=6)\n",
    "        reg.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "        rf.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "    for mod in [reg,rf]:\n",
    "        print (\"-----\")\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        for a,data in enumerate(testloader):\n",
    "            imagesp, labelsp = data\n",
    "            predicted = mod.predict(imagesp[:,:,:,:].numpy().reshape(500,-1))\n",
    "            c = (predicted == labelsp).squeeze()\n",
    "            for i in range(500):\n",
    "                label = labelsp[i]\n",
    "                class_correct[label] += c[i]\n",
    "                class_total[label] += 1\n",
    "            if a>=4:\n",
    "                break \n",
    "        for i in range(10):\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print np.sum(class_correct)/np.sum(class_total)\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nest is 500\n",
      "((7000, 512), torch.Size([7000]))\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=700, n_jobs=6,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Accuracy of plane : 40 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 21 %\n",
      "Accuracy of   cat :  9 %\n",
      "Accuracy of  deer : 29 %\n",
      "Accuracy of   dog : 37 %\n",
      "Accuracy of  frog : 56 %\n",
      "Accuracy of horse : 44 %\n",
      "Accuracy of  ship : 51 %\n",
      "Accuracy of truck : 39 %\n",
      "0.3788\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=300, multi_class='ovr', n_jobs=6,\n",
      "          penalty='l1', random_state=None, solver='saga', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Accuracy of plane : 45 %\n",
      "Accuracy of   car : 54 %\n",
      "Accuracy of  bird : 27 %\n",
      "Accuracy of   cat : 20 %\n",
      "Accuracy of  deer : 34 %\n",
      "Accuracy of   dog : 31 %\n",
      "Accuracy of  frog : 63 %\n",
      "Accuracy of horse : 49 %\n",
      "Accuracy of  ship : 58 %\n",
      "Accuracy of truck : 46 %\n",
      "0.4344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model,metrics,preprocessing\n",
    "\n",
    "\n",
    "for ty,data in enumerate(trainloader):\n",
    "    mrand_Net = rand_Net_3() \n",
    "    images, labels = data\n",
    "    outputs = mrand_Net(Variable(images))\n",
    "    if True: #for nest in [500]:#np.logspace(0,3,10):\n",
    "        print('nest is %s'%nest)\n",
    "        print(outputs.data.numpy().shape, labels.shape)\n",
    "        rf = RandomForestClassifier(n_estimators=700, n_jobs=6)\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=300)\n",
    "        \n",
    "        rf.fit(outputs.data.numpy(), labels) \n",
    "        reg.fit(outputs.data.numpy(), labels) \n",
    "        \n",
    "        for mod in [rf,reg]:\n",
    "            print(mod)\n",
    "            class_correct = list(0. for i in range(10))\n",
    "            class_total = list(0. for i in range(10))\n",
    "            for a, data in enumerate(testloader):\n",
    "                imagesp, labelsp = data\n",
    "                outputsp = mrand_Net(Variable(imagesp))\n",
    "                predicted = mod.predict(outputsp.data.numpy())\n",
    "                c = (predicted == labelsp).squeeze()\n",
    "                for i in range(500):\n",
    "                    label = labelsp[i]\n",
    "                    class_correct[label] += c[i]\n",
    "                    class_total[label] += 1\n",
    "                if a>=4:\n",
    "                    break   \n",
    "            for i in range(10):\n",
    "                print('Accuracy of %5s : %2d %%' % (\n",
    "                    classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "            print np.sum(class_correct)/np.sum(class_total)\n",
    "        #L.append(metrics.log_loss(np.array(labels_t),yout ,labels=range(10)))       \n",
    "    #print(L, L_lr) \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
