{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "torch.set_num_threads(8)\n",
    "os.environ['MKL_NUM_THREADS'] = \"8\"\n",
    "os.environ['OMP_NUM_THREADS'] = \"8\"\n",
    "OMP_NUM_THREADS=8\n",
    "MKL_NUM_THREADS=8\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "transform = transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 2 every 30 epochs\"\"\"\n",
    "    lr = 0.05 * (0.5 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def train_eval(net,n_epochs=50):\n",
    "    losses=[]\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "\n",
    "            # wrap them in Variable\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs, fcw = net(inputs)\n",
    "\n",
    "            #optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), lr=0.001, momentum=0.9)\n",
    "            \n",
    "            optimizer = optim.SGD(filter(lambda p: p.requires_grad, net.parameters()), \n",
    "                                  lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
    "            adjust_learning_rate(optimizer, epoch)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            l1 = torch.abs(fcw).sum()\n",
    "            #print('CRIT', criterion(outputs, labels))\n",
    "            #print('L1', l1)\n",
    "\n",
    "            loss = criterion(outputs, labels) #+ 0.001*l1\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 2000))\n",
    "                losses.append(running_loss/ 2000)\n",
    "                running_loss = 0.0\n",
    "                #print('L1 = %s'%l1)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    plt.plot(losses)\n",
    "\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs,_ = net(Variable(images).cuda())\n",
    "        _, predicted = torch.max(outputs.data.cpu(), 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(8):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i]\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "    for i in range(10):\n",
    "        print('Accuracy of %5s : %2d %%' % (\n",
    "            classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "    print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layer randCNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_Net3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 512, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.934\n",
      "[2,  2000] loss: 1.686\n",
      "[3,  2000] loss: 1.600\n",
      "[4,  2000] loss: 1.546\n",
      "[5,  2000] loss: 1.518\n",
      "[6,  2000] loss: 1.487\n",
      "[7,  2000] loss: 1.468\n",
      "[8,  2000] loss: 1.456\n",
      "[9,  2000] loss: 1.449\n",
      "[10,  2000] loss: 1.433\n",
      "[11,  2000] loss: 1.423\n",
      "[12,  2000] loss: 1.423\n",
      "[13,  2000] loss: 1.412\n",
      "[14,  2000] loss: 1.404\n",
      "[15,  2000] loss: 1.397\n",
      "[16,  2000] loss: 1.401\n",
      "[17,  2000] loss: 1.393\n",
      "[18,  2000] loss: 1.391\n",
      "[19,  2000] loss: 1.394\n",
      "[20,  2000] loss: 1.395\n",
      "[21,  2000] loss: 1.378\n",
      "[22,  2000] loss: 1.387\n",
      "[23,  2000] loss: 1.378\n",
      "[24,  2000] loss: 1.379\n",
      "[25,  2000] loss: 1.376\n",
      "[26,  2000] loss: 1.375\n",
      "[27,  2000] loss: 1.378\n",
      "[28,  2000] loss: 1.373\n",
      "[29,  2000] loss: 1.384\n",
      "[30,  2000] loss: 1.378\n",
      "[31,  2000] loss: 1.301\n",
      "[32,  2000] loss: 1.301\n",
      "[33,  2000] loss: 1.305\n",
      "[34,  2000] loss: 1.307\n",
      "[35,  2000] loss: 1.302\n",
      "[36,  2000] loss: 1.303\n",
      "[37,  2000] loss: 1.306\n",
      "[38,  2000] loss: 1.308\n",
      "[39,  2000] loss: 1.302\n",
      "[40,  2000] loss: 1.301\n",
      "[41,  2000] loss: 1.309\n",
      "[42,  2000] loss: 1.306\n",
      "[43,  2000] loss: 1.301\n",
      "[44,  2000] loss: 1.303\n",
      "[45,  2000] loss: 1.309\n",
      "[46,  2000] loss: 1.303\n",
      "[47,  2000] loss: 1.307\n",
      "[48,  2000] loss: 1.302\n",
      "[49,  2000] loss: 1.305\n",
      "[50,  2000] loss: 1.308\n",
      "[51,  2000] loss: 1.308\n",
      "[52,  2000] loss: 1.306\n",
      "[53,  2000] loss: 1.304\n",
      "[54,  2000] loss: 1.301\n",
      "[55,  2000] loss: 1.305\n",
      "[56,  2000] loss: 1.299\n",
      "[57,  2000] loss: 1.304\n",
      "[58,  2000] loss: 1.309\n",
      "[59,  2000] loss: 1.307\n",
      "[60,  2000] loss: 1.307\n",
      "[61,  2000] loss: 1.288\n",
      "[62,  2000] loss: 1.276\n",
      "[63,  2000] loss: 1.281\n",
      "[64,  2000] loss: 1.278\n",
      "[65,  2000] loss: 1.285\n",
      "[66,  2000] loss: 1.283\n",
      "[67,  2000] loss: 1.280\n"
     ]
    }
   ],
   "source": [
    "net3 = rand_Net3()\n",
    "net3.cuda()\n",
    "train_eval(net3,n_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with different random init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_Net3_lap(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net3_lap, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(128, 512, 3,padding=1)\n",
    "        self.fc = nn.Linear(4096*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        for k in range(self.conv1.weight.data.shape[1]):\n",
    "            self.conv1.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        for k in range(self.conv2.weight.data.shape[1]):\n",
    "            self.conv2.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        for k in range(self.conv3.weight.data.shape[1]):\n",
    "            self.conv3.weight.data[k,0,:,:] = torch.FloatTensor(np.matmul(np.random.laplace(0,1./3,(3,1)),np.random.laplace(0,1./3,(1,3))))\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.263\n",
      "[2,  2000] loss: 1.264\n",
      "[3,  2000] loss: 1.260\n",
      "[4,  2000] loss: 1.258\n",
      "[5,  2000] loss: 1.259\n",
      "[6,  2000] loss: 1.263\n",
      "[7,  2000] loss: 1.260\n",
      "[8,  2000] loss: 1.258\n",
      "[9,  2000] loss: 1.256\n",
      "[10,  2000] loss: 1.253\n",
      "[11,  2000] loss: 1.253\n",
      "[12,  2000] loss: 1.249\n",
      "[13,  2000] loss: 1.250\n",
      "[14,  2000] loss: 1.250\n",
      "[15,  2000] loss: 1.247\n",
      "[16,  2000] loss: 1.254\n",
      "[17,  2000] loss: 1.250\n",
      "[18,  2000] loss: 1.245\n",
      "[19,  2000] loss: 1.245\n",
      "[20,  2000] loss: 1.244\n",
      "[21,  2000] loss: 1.246\n",
      "[22,  2000] loss: 1.248\n",
      "[23,  2000] loss: 1.245\n",
      "[24,  2000] loss: 1.239\n",
      "[25,  2000] loss: 1.240\n",
      "[26,  2000] loss: 1.234\n",
      "[27,  2000] loss: 1.241\n",
      "[28,  2000] loss: 1.237\n",
      "[29,  2000] loss: 1.243\n",
      "[30,  2000] loss: 1.242\n",
      "[31,  2000] loss: 1.235\n",
      "[32,  2000] loss: 1.235\n",
      "[33,  2000] loss: 1.231\n",
      "[34,  2000] loss: 1.235\n",
      "[35,  2000] loss: 1.233\n",
      "[36,  2000] loss: 1.229\n",
      "[37,  2000] loss: 1.233\n",
      "[38,  2000] loss: 1.230\n",
      "[39,  2000] loss: 1.228\n",
      "[40,  2000] loss: 1.233\n",
      "[41,  2000] loss: 1.231\n",
      "[42,  2000] loss: 1.233\n",
      "[43,  2000] loss: 1.226\n",
      "[44,  2000] loss: 1.228\n",
      "[45,  2000] loss: 1.224\n",
      "[46,  2000] loss: 1.221\n",
      "[47,  2000] loss: 1.224\n",
      "[48,  2000] loss: 1.224\n",
      "[49,  2000] loss: 1.221\n",
      "[50,  2000] loss: 1.225\n",
      "Finished Training\n",
      "Accuracy of plane : 59 %\n",
      "Accuracy of   car : 66 %\n",
      "Accuracy of  bird : 39 %\n",
      "Accuracy of   cat : 37 %\n",
      "Accuracy of  deer : 49 %\n",
      "Accuracy of   dog : 45 %\n",
      "Accuracy of  frog : 69 %\n",
      "Accuracy of horse : 62 %\n",
      "Accuracy of  ship : 73 %\n",
      "Accuracy of truck : 62 %\n",
      "0.5654\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9e6501fa50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#net3l = rand_Net3_lap()\n",
    "net3l.cuda()\n",
    "train_eval(net3l,n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.773\n",
      "[2,  2000] loss: 1.470\n",
      "[3,  2000] loss: 1.392\n",
      "[4,  2000] loss: 1.348\n",
      "[5,  2000] loss: 1.306\n",
      "[6,  2000] loss: 1.287\n",
      "[7,  2000] loss: 1.260\n",
      "[8,  2000] loss: 1.251\n",
      "[9,  2000] loss: 1.238\n",
      "[10,  2000] loss: 1.225\n",
      "[11,  2000] loss: 1.218\n",
      "[12,  2000] loss: 1.217\n",
      "[13,  2000] loss: 1.202\n",
      "[14,  2000] loss: 1.199\n",
      "[15,  2000] loss: 1.195\n",
      "[16,  2000] loss: 1.186\n",
      "[17,  2000] loss: 1.187\n",
      "[18,  2000] loss: 1.180\n",
      "[19,  2000] loss: 1.180\n",
      "[20,  2000] loss: 1.178\n",
      "[21,  2000] loss: 1.171\n",
      "[22,  2000] loss: 1.174\n",
      "[23,  2000] loss: 1.176\n",
      "[24,  2000] loss: 1.165\n",
      "[25,  2000] loss: 1.166\n",
      "[26,  2000] loss: 1.162\n",
      "[27,  2000] loss: 1.163\n",
      "[28,  2000] loss: 1.168\n",
      "[29,  2000] loss: 1.164\n",
      "[30,  2000] loss: 1.164\n",
      "[31,  2000] loss: 1.145\n",
      "[32,  2000] loss: 1.148\n",
      "[33,  2000] loss: 1.139\n",
      "[34,  2000] loss: 1.146\n",
      "[35,  2000] loss: 1.146\n",
      "[36,  2000] loss: 1.148\n",
      "[37,  2000] loss: 1.145\n",
      "[38,  2000] loss: 1.146\n",
      "[39,  2000] loss: 1.141\n",
      "[40,  2000] loss: 1.142\n",
      "[41,  2000] loss: 1.138\n",
      "[42,  2000] loss: 1.139\n",
      "[43,  2000] loss: 1.143\n",
      "[44,  2000] loss: 1.143\n",
      "[45,  2000] loss: 1.143\n",
      "[46,  2000] loss: 1.147\n",
      "[47,  2000] loss: 1.142\n",
      "[48,  2000] loss: 1.142\n",
      "[49,  2000] loss: 1.139\n",
      "[50,  2000] loss: 1.145\n",
      "[51,  2000] loss: 1.141\n",
      "[52,  2000] loss: 1.143\n",
      "[53,  2000] loss: 1.140\n",
      "[54,  2000] loss: 1.142\n",
      "[55,  2000] loss: 1.140\n",
      "[56,  2000] loss: 1.139\n",
      "[57,  2000] loss: 1.142\n",
      "[58,  2000] loss: 1.144\n",
      "[59,  2000] loss: 1.138\n",
      "[60,  2000] loss: 1.136\n",
      "[61,  2000] loss: 1.130\n",
      "[62,  2000] loss: 1.133\n",
      "[63,  2000] loss: 1.136\n",
      "[64,  2000] loss: 1.129\n",
      "[65,  2000] loss: 1.132\n",
      "[66,  2000] loss: 1.134\n",
      "[67,  2000] loss: 1.132\n",
      "[68,  2000] loss: 1.135\n",
      "[69,  2000] loss: 1.133\n",
      "[70,  2000] loss: 1.133\n",
      "[71,  2000] loss: 1.134\n",
      "[72,  2000] loss: 1.131\n",
      "[73,  2000] loss: 1.129\n",
      "[74,  2000] loss: 1.131\n",
      "[75,  2000] loss: 1.132\n",
      "[76,  2000] loss: 1.133\n",
      "[77,  2000] loss: 1.136\n",
      "[78,  2000] loss: 1.131\n",
      "[79,  2000] loss: 1.130\n",
      "[80,  2000] loss: 1.135\n",
      "[81,  2000] loss: 1.132\n",
      "[82,  2000] loss: 1.129\n",
      "[83,  2000] loss: 1.129\n",
      "[84,  2000] loss: 1.131\n",
      "[85,  2000] loss: 1.134\n",
      "[86,  2000] loss: 1.129\n",
      "[87,  2000] loss: 1.132\n",
      "[88,  2000] loss: 1.132\n",
      "[89,  2000] loss: 1.130\n",
      "[90,  2000] loss: 1.132\n",
      "[91,  2000] loss: 1.127\n",
      "[92,  2000] loss: 1.129\n",
      "[93,  2000] loss: 1.125\n",
      "[94,  2000] loss: 1.130\n",
      "[95,  2000] loss: 1.131\n",
      "[96,  2000] loss: 1.129\n",
      "[97,  2000] loss: 1.125\n",
      "[98,  2000] loss: 1.128\n",
      "[99,  2000] loss: 1.130\n",
      "[100,  2000] loss: 1.126\n",
      "[101,  2000] loss: 1.127\n",
      "[102,  2000] loss: 1.134\n",
      "[103,  2000] loss: 1.127\n",
      "[104,  2000] loss: 1.130\n",
      "[105,  2000] loss: 1.133\n",
      "[106,  2000] loss: 1.127\n",
      "[107,  2000] loss: 1.129\n",
      "[108,  2000] loss: 1.128\n",
      "[109,  2000] loss: 1.127\n",
      "[110,  2000] loss: 1.126\n",
      "[111,  2000] loss: 1.129\n",
      "[112,  2000] loss: 1.124\n",
      "[113,  2000] loss: 1.127\n",
      "[114,  2000] loss: 1.131\n",
      "[115,  2000] loss: 1.131\n",
      "[116,  2000] loss: 1.130\n",
      "[117,  2000] loss: 1.129\n",
      "[118,  2000] loss: 1.124\n",
      "[119,  2000] loss: 1.126\n",
      "[120,  2000] loss: 1.125\n",
      "[121,  2000] loss: 1.127\n",
      "[122,  2000] loss: 1.124\n",
      "[123,  2000] loss: 1.122\n",
      "[124,  2000] loss: 1.123\n",
      "[125,  2000] loss: 1.126\n",
      "[126,  2000] loss: 1.125\n",
      "[127,  2000] loss: 1.127\n",
      "[128,  2000] loss: 1.129\n",
      "[129,  2000] loss: 1.123\n",
      "[130,  2000] loss: 1.125\n",
      "[131,  2000] loss: 1.132\n",
      "[132,  2000] loss: 1.125\n",
      "[133,  2000] loss: 1.122\n",
      "[134,  2000] loss: 1.130\n",
      "[135,  2000] loss: 1.124\n",
      "[136,  2000] loss: 1.124\n",
      "[137,  2000] loss: 1.123\n",
      "[138,  2000] loss: 1.124\n",
      "[139,  2000] loss: 1.124\n",
      "[140,  2000] loss: 1.125\n",
      "[141,  2000] loss: 1.126\n",
      "[142,  2000] loss: 1.126\n",
      "[143,  2000] loss: 1.128\n",
      "[144,  2000] loss: 1.127\n",
      "[145,  2000] loss: 1.129\n",
      "[146,  2000] loss: 1.122\n",
      "[147,  2000] loss: 1.121\n",
      "[148,  2000] loss: 1.122\n",
      "[149,  2000] loss: 1.123\n",
      "[150,  2000] loss: 1.126\n",
      "[151,  2000] loss: 1.124\n",
      "[152,  2000] loss: 1.129\n",
      "[153,  2000] loss: 1.124\n",
      "[154,  2000] loss: 1.125\n",
      "[155,  2000] loss: 1.129\n",
      "[156,  2000] loss: 1.122\n",
      "[157,  2000] loss: 1.126\n",
      "[158,  2000] loss: 1.125\n",
      "[159,  2000] loss: 1.129\n",
      "[160,  2000] loss: 1.125\n",
      "[161,  2000] loss: 1.121\n",
      "[162,  2000] loss: 1.124\n",
      "[163,  2000] loss: 1.127\n",
      "[164,  2000] loss: 1.127\n",
      "[165,  2000] loss: 1.127\n",
      "[166,  2000] loss: 1.125\n",
      "[167,  2000] loss: 1.127\n",
      "[168,  2000] loss: 1.122\n",
      "[169,  2000] loss: 1.126\n",
      "[170,  2000] loss: 1.126\n",
      "[171,  2000] loss: 1.121\n",
      "[172,  2000] loss: 1.123\n",
      "[173,  2000] loss: 1.126\n",
      "[174,  2000] loss: 1.122\n",
      "[175,  2000] loss: 1.122\n",
      "[176,  2000] loss: 1.124\n",
      "[177,  2000] loss: 1.127\n",
      "[178,  2000] loss: 1.127\n",
      "[179,  2000] loss: 1.121\n",
      "[180,  2000] loss: 1.124\n",
      "[181,  2000] loss: 1.126\n",
      "[182,  2000] loss: 1.123\n",
      "[183,  2000] loss: 1.125\n",
      "[184,  2000] loss: 1.127\n",
      "[185,  2000] loss: 1.125\n",
      "[186,  2000] loss: 1.123\n",
      "[187,  2000] loss: 1.125\n",
      "[188,  2000] loss: 1.120\n",
      "[189,  2000] loss: 1.126\n",
      "[190,  2000] loss: 1.124\n",
      "[191,  2000] loss: 1.126\n",
      "[192,  2000] loss: 1.129\n",
      "[193,  2000] loss: 1.130\n",
      "[194,  2000] loss: 1.119\n",
      "[195,  2000] loss: 1.127\n",
      "[196,  2000] loss: 1.130\n",
      "[197,  2000] loss: 1.126\n",
      "[198,  2000] loss: 1.124\n",
      "[199,  2000] loss: 1.122\n",
      "[200,  2000] loss: 1.125\n",
      "Finished Training\n",
      "Accuracy of plane : 62 %\n",
      "Accuracy of   car : 71 %\n",
      "Accuracy of  bird : 47 %\n",
      "Accuracy of   cat : 42 %\n",
      "Accuracy of  deer : 52 %\n",
      "Accuracy of   dog : 49 %\n",
      "Accuracy of  frog : 70 %\n",
      "Accuracy of horse : 67 %\n",
      "Accuracy of  ship : 76 %\n",
      "Accuracy of truck : 67 %\n",
      "0.6084\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9dfc6dee10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net3l_ = rand_Net3_lap()\n",
    "net3l_.cuda()\n",
    "train_eval(net3l_,n_epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rand_Net4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_Net4, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32*2, 3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32*2, 64*2, 3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64*2, 128*2, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128*2, 512*2, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(2048*2, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),kernel_size=2, stride=2)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, 's'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.298\n",
      "[2,  2000] loss: 2.281\n",
      "[3,  2000] loss: 2.264\n",
      "[4,  2000] loss: 2.249\n",
      "[5,  2000] loss: 2.235\n",
      "[6,  2000] loss: 2.221\n",
      "[7,  2000] loss: 2.209\n",
      "[8,  2000] loss: 2.197\n",
      "[9,  2000] loss: 2.186\n",
      "[10,  2000] loss: 2.174\n",
      "[11,  2000] loss: 2.166\n",
      "[12,  2000] loss: 2.155\n",
      "[13,  2000] loss: 2.144\n",
      "[14,  2000] loss: 2.138\n",
      "[15,  2000] loss: 2.125\n",
      "[16,  2000] loss: 2.122\n",
      "[17,  2000] loss: 2.109\n",
      "[18,  2000] loss: 2.104\n",
      "[19,  2000] loss: 2.101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-38:\n",
      "Process Process-37:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/process.py\", line 267, in _bootstrap\n",
      "    self.run()\n",
      "    self.run()\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/process.py\", line 114, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/utils/data/dataloader.py\", line 36, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "    r = index_queue.get()\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/queues.py\", line 376, in get\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/multiprocessing/queues.py\", line 374, in get\n",
      "    return recv()\n",
      "    racquire()\n",
      "  File \"/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/multiprocessing/queue.py\", line 21, in recv\n",
      "KeyboardInterrupt\n",
      "    buf = self.recv_bytes()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bb74d7336765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-4c682ad8d138>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/nn/modules/conv.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 277\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/homes/cdt17/yuki/.conda/envs/py27/lib/python2.7/site-packages/torch/nn/functional.pyc\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0m_pair\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 torch.backends.cudnn.deterministic, torch.backends.cudnn.enabled)\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net4 = rand_Net4()\n",
    "net4.cuda()\n",
    "train_eval(net4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try deeper network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vgg11 [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "   \n",
    "class rand_vgg11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(rand_vgg11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3,padding=1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128*2, 3,padding=1)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128*2, 256*2, 3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(256*2, 256*2, 3,padding=1)\n",
    "                \n",
    "        self.conv5 = nn.Conv2d(256*2, 512*4, 3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "        \n",
    "        self.conv7 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "        self.conv8 = nn.Conv2d(512*4, 512*4, 3,padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(512*4, 10)\n",
    "        for p in self.conv1.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv2.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv3.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv4.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv5.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv6.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv7.parameters():\n",
    "            p.requires_grad = False\n",
    "        for p in self.conv8.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)),kernel_size=2, stride=2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv4(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv6(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = F.relu(self.conv7(x))\n",
    "        x = F.max_pool2d(F.relu(self.conv8(x)),kernel_size=2, stride=2)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x, self.fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netvgg11 = rand_vgg11()\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "losses=[]\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, fcw = netvgg11(inputs)\n",
    "                \n",
    "        optimizer = optim.SGD(filter(lambda p: p.requires_grad, netvgg11.parameters()), lr=0.001, momentum=0.9)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #l1 = torch.abs(fcw).sum()\n",
    "        #print('CRIT', criterion(outputs, labels))\n",
    "        #print('L1', l1)\n",
    "        \n",
    "        loss = criterion(outputs, labels) #+ 0.001*l1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "    losses.append(loss.data[0])\n",
    "plt.plot(losses)\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane :  0 %\n",
      "Accuracy of   car :  0 %\n",
      "Accuracy of  bird :  0 %\n",
      "Accuracy of   cat :  0 %\n",
      "Accuracy of  deer : 100 %\n",
      "Accuracy of   dog :  0 %\n",
      "Accuracy of  frog :  0 %\n",
      "Accuracy of horse :  0 %\n",
      "Accuracy of  ship :  0 %\n",
      "Accuracy of truck :  0 %\n",
      "0.1\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs,_ = netvgg11(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze()\n",
    "    for i in range(8):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print np.sum(class_correct)/np.sum(class_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to pixel by pixel Lasso classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=7000,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=500,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute purely on pixels\n",
      "1\n",
      "-----\n",
      "Accuracy of plane : 43 %\n",
      "Accuracy of   car : 43 %\n",
      "Accuracy of  bird : 26 %\n",
      "Accuracy of   cat : 17 %\n",
      "Accuracy of  deer : 28 %\n",
      "Accuracy of   dog : 27 %\n",
      "Accuracy of  frog : 48 %\n",
      "Accuracy of horse : 48 %\n",
      "Accuracy of  ship : 53 %\n",
      "Accuracy of truck : 41 %\n",
      "0.3804\n",
      "-----\n",
      "Accuracy of plane : 46 %\n",
      "Accuracy of   car : 46 %\n",
      "Accuracy of  bird : 33 %\n",
      "Accuracy of   cat : 21 %\n",
      "Accuracy of  deer : 32 %\n",
      "Accuracy of   dog : 36 %\n",
      "Accuracy of  frog : 51 %\n",
      "Accuracy of horse : 45 %\n",
      "Accuracy of  ship : 66 %\n",
      "Accuracy of truck : 51 %\n",
      "0.4368\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model,metrics,preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "print('compute purely on pixels')\n",
    "for ty,data in enumerate(trainloader):\n",
    "    images, labels = data\n",
    "    for alpha in [1]:#np.logspace(0,3,10):\n",
    "        print alpha\n",
    "        reg = linear_model.LogisticRegression(penalty='l1',solver ='saga',C = alpha,n_jobs=6,max_iter=3)\n",
    "        rf = RandomForestClassifier(n_estimators = 300,n_jobs=6)\n",
    "        reg.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "        rf.fit(images[:,:,:,:].numpy().reshape(7000,-1) , labels) \n",
    "    for mod in [reg,rf]:\n",
    "        print (\"-----\")\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        for a,data in enumerate(testloader):\n",
    "            imagesp, labelsp = data\n",
    "            predicted = mod.predict(imagesp[:,:,:,:].numpy().reshape(500,-1))\n",
    "            c = (predicted == labelsp).squeeze()\n",
    "            for i in range(500):\n",
    "                label = labelsp[i]\n",
    "                class_correct[label] += c[i]\n",
    "                class_total[label] += 1\n",
    "            if a>=4:\n",
    "                break \n",
    "        for i in range(10):\n",
    "            print('Accuracy of %5s : %2d %%' % (\n",
    "                classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print np.sum(class_correct)/np.sum(class_total)\n",
    "    break\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
